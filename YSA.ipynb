{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69e576c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d9e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit = pd.read_csv(\"Hitters.csv\")\n",
    "df = hit.copy()\n",
    "df = df.dropna()\n",
    "\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "\n",
    "y = df[\"Salary\"]\n",
    "\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], \n",
    "             axis = 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "054e1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verilerin ölçeklendilirmesi\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40ed4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yapay Sinir Ağı modeli oluşturmaa\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "ysa_model = Sequential()\n",
    "ysa_model.add(Dense(units=64, activation=\"relu\", input_dim=X_train.shape[1]))\n",
    "ysa_model.add(Dense(units=32, activation=\"relu\"))\n",
    "ysa_model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a95a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli derleyin\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "ysa_model.compile(optimizer=optimizer, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88473cea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 104990.3828\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 906us/step - loss: 104583.7500\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 754us/step - loss: 104274.2344\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 662us/step - loss: 103902.9141\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 612us/step - loss: 103511.7188\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 699us/step - loss: 103206.6406\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 602us/step - loss: 102872.4531\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 633us/step - loss: 102542.8359\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 661us/step - loss: 102201.4609\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 606us/step - loss: 101922.5469\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 629us/step - loss: 101592.5469\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 601us/step - loss: 101351.0156\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 571us/step - loss: 100988.8594\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 733us/step - loss: 100613.8516\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 594us/step - loss: 100478.8594\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 541us/step - loss: 100157.2969\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 659us/step - loss: 99991.9688\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 651us/step - loss: 99695.4297\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 657us/step - loss: 99413.3828\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 723us/step - loss: 99362.1797\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 513us/step - loss: 98709.8984\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 617us/step - loss: 98444.2344\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 592us/step - loss: 98112.2031\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 593us/step - loss: 97783.7734\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 630us/step - loss: 97631.2656\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 533us/step - loss: 97505.3516\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 642us/step - loss: 97074.5469\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 516us/step - loss: 96930.3438\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 568us/step - loss: 96615.6016\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 717us/step - loss: 96304.6875\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 719us/step - loss: 96061.4297\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 625us/step - loss: 95834.0000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 547us/step - loss: 95632.5547\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 583us/step - loss: 95445.0234\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 645us/step - loss: 95288.7734\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 719us/step - loss: 95077.4453\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 608us/step - loss: 94850.1719\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 617us/step - loss: 94682.7812\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 617us/step - loss: 94429.8750\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 532us/step - loss: 94110.9141\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 686us/step - loss: 94041.7969\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 721us/step - loss: 93805.2500\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 610us/step - loss: 93653.9766\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 621us/step - loss: 93514.7344\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 622us/step - loss: 93310.1719\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 546us/step - loss: 93108.7812\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 646us/step - loss: 92875.7500\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 547us/step - loss: 92807.9375\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 634us/step - loss: 92547.8906\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 808us/step - loss: 92493.3594\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 663us/step - loss: 92212.2656\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 586us/step - loss: 91985.2500\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 688us/step - loss: 91867.9688\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 631us/step - loss: 91802.3047\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 629us/step - loss: 91621.4297\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 728us/step - loss: 91465.7344\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 868us/step - loss: 91353.6328\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 523us/step - loss: 91156.0625\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 610us/step - loss: 91073.5156\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 90932.4141\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 601us/step - loss: 90879.6172\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 629us/step - loss: 90706.9766\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 643us/step - loss: 90495.9688\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 528us/step - loss: 90445.9766\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 678us/step - loss: 90366.2109\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 609us/step - loss: 90242.2656\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 90150.8828\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 639us/step - loss: 89979.8047\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 612us/step - loss: 89832.5547\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 636us/step - loss: 89650.0312\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 593us/step - loss: 89611.5000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 562us/step - loss: 89419.8516\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 532us/step - loss: 89606.7812\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 615us/step - loss: 89534.7109\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 647us/step - loss: 89452.1250\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 660us/step - loss: 89345.6562\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 773us/step - loss: 89143.0781\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 589us/step - loss: 89080.9141\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 613us/step - loss: 88944.6016\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 637us/step - loss: 88975.0078\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 689us/step - loss: 88972.4531\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 531us/step - loss: 88605.0625\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 742us/step - loss: 88517.7031\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 519us/step - loss: 88379.8594\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 618us/step - loss: 88272.7031\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 688us/step - loss: 88137.5312\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 611us/step - loss: 87916.7891\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 620us/step - loss: 87775.2500\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 671us/step - loss: 87780.1328\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 621us/step - loss: 87664.4062\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 600us/step - loss: 87636.0625\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 629us/step - loss: 87557.1641\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 556us/step - loss: 87282.1250\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 656us/step - loss: 87140.7812\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 598us/step - loss: 87304.4141\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 648us/step - loss: 87039.4922\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 710us/step - loss: 86976.5078\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 598us/step - loss: 86801.0078\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 608us/step - loss: 86687.9531\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 655us/step - loss: 86636.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175c823a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model eğitimi\n",
    "ysa_model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2059ec",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f42a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 762us/step\n"
     ]
    }
   ],
   "source": [
    "# Model tahminleri\n",
    "y_pred = ysa_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3515ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  355.25331093825605\n",
      "R2:  0.4170023212144993\n"
     ]
    }
   ],
   "source": [
    "# Hata ölçümleri\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE: \", np.sqrt(mse))\n",
    "print(\"R2: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab012265",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9aacab86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 714us/step - loss: 462908.1875\n",
      "3/3 [==============================] - 0s 740us/step - loss: 543130.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/k116mkp91b14gpcf_ggn7cn80000gn/T/ipykernel_78609/2088236660.py:17: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  regressor = KerasRegressor(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 694us/step - loss: 452036.5000\n",
      "3/3 [==============================] - 0s 668us/step - loss: 568105.8750\n",
      "5/5 [==============================] - 0s 651us/step - loss: 561327.6250\n",
      "3/3 [==============================] - 0s 752us/step - loss: 353784.5000\n",
      "5/5 [==============================] - 0s 709us/step - loss: 462746.9062\n",
      "3/3 [==============================] - 0s 769us/step - loss: 543491.7500\n",
      "5/5 [==============================] - 0s 659us/step - loss: 451740.0938\n",
      "3/3 [==============================] - 0s 743us/step - loss: 566836.9375\n",
      "5/5 [==============================] - 0s 819us/step - loss: 560568.1250\n",
      "3/3 [==============================] - 0s 783us/step - loss: 352587.6250\n",
      "5/5 [==============================] - 0s 738us/step - loss: 462769.7188\n",
      "3/3 [==============================] - 0s 953us/step - loss: 541972.0625\n",
      "5/5 [==============================] - 0s 743us/step - loss: 451626.2500\n",
      "3/3 [==============================] - 0s 787us/step - loss: 564151.8125\n",
      "5/5 [==============================] - 0s 759us/step - loss: 558437.0625\n",
      "3/3 [==============================] - 0s 744us/step - loss: 348393.2812\n",
      "5/5 [==============================] - 0s 734us/step - loss: 463650.3750\n",
      "3/3 [==============================] - 0s 741us/step - loss: 544963.0625\n",
      "5/5 [==============================] - 0s 652us/step - loss: 451337.2188\n",
      "3/3 [==============================] - 0s 764us/step - loss: 564068.1875\n",
      "5/5 [==============================] - 0s 677us/step - loss: 559591.5000\n",
      "3/3 [==============================] - 0s 937us/step - loss: 350843.8438\n",
      "5/5 [==============================] - 0s 757us/step - loss: 462566.4375\n",
      "3/3 [==============================] - 0s 773us/step - loss: 540999.0625\n",
      "5/5 [==============================] - 0s 764us/step - loss: 450797.9375\n",
      "3/3 [==============================] - 0s 721us/step - loss: 561335.3125\n",
      "5/5 [==============================] - 0s 699us/step - loss: 559514.1875\n",
      "3/3 [==============================] - 0s 736us/step - loss: 350570.8125\n",
      "5/5 [==============================] - 0s 689us/step - loss: 461336.8125\n",
      "3/3 [==============================] - 0s 731us/step - loss: 535371.3750\n",
      "5/5 [==============================] - 0s 681us/step - loss: 450610.9688\n",
      "3/3 [==============================] - 0s 756us/step - loss: 558340.9375\n",
      "5/5 [==============================] - 0s 747us/step - loss: 557333.2500\n",
      "3/3 [==============================] - 0s 950us/step - loss: 343218.6250\n",
      "5/5 [==============================] - 0s 710us/step - loss: 462393.5625\n",
      "3/3 [==============================] - 0s 707us/step - loss: 540376.5625\n",
      "5/5 [==============================] - 0s 778us/step - loss: 451298.6250\n",
      "3/3 [==============================] - 0s 811us/step - loss: 563099.6875\n",
      "5/5 [==============================] - 0s 742us/step - loss: 558846.3125\n",
      "3/3 [==============================] - 0s 798us/step - loss: 348878.8750\n",
      "5/5 [==============================] - 0s 722us/step - loss: 461315.2500\n",
      "3/3 [==============================] - 0s 750us/step - loss: 535901.7500\n",
      "5/5 [==============================] - 0s 740us/step - loss: 451063.6875\n",
      "3/3 [==============================] - 0s 780us/step - loss: 560019.5625\n",
      "5/5 [==============================] - 0s 694us/step - loss: 557634.1875\n",
      "3/3 [==============================] - 0s 708us/step - loss: 343123.3438\n",
      "5/5 [==============================] - 0s 765us/step - loss: 460419.3438\n",
      "3/3 [==============================] - 0s 723us/step - loss: 531990.0625\n",
      "5/5 [==============================] - 0s 791us/step - loss: 448733.2812\n",
      "3/3 [==============================] - 0s 764us/step - loss: 548436.6250\n",
      "5/5 [==============================] - 0s 741us/step - loss: 556530.0000\n",
      "3/3 [==============================] - 0s 708us/step - loss: 337212.0625\n",
      "5/5 [==============================] - 0s 646us/step - loss: 465628.6562\n",
      "3/3 [==============================] - 0s 705us/step - loss: 549666.1875\n",
      "5/5 [==============================] - 0s 728us/step - loss: 452897.9688\n",
      "3/3 [==============================] - 0s 746us/step - loss: 572419.5000\n",
      "5/5 [==============================] - 0s 700us/step - loss: 561702.1875\n",
      "3/3 [==============================] - 0s 776us/step - loss: 355540.9062\n",
      "5/5 [==============================] - 0s 744us/step - loss: 465057.1250\n",
      "3/3 [==============================] - 0s 722us/step - loss: 549308.9375\n",
      "5/5 [==============================] - 0s 725us/step - loss: 453074.4688\n",
      "3/3 [==============================] - 0s 726us/step - loss: 572481.7500\n",
      "5/5 [==============================] - 0s 630us/step - loss: 561728.7500\n",
      "3/3 [==============================] - 0s 803us/step - loss: 355658.5000\n",
      "5/5 [==============================] - 0s 701us/step - loss: 465040.3438\n",
      "3/3 [==============================] - 0s 768us/step - loss: 549092.8125\n",
      "5/5 [==============================] - 0s 751us/step - loss: 452979.7812\n",
      "3/3 [==============================] - 0s 891us/step - loss: 572127.2500\n",
      "5/5 [==============================] - 0s 767us/step - loss: 561116.3750\n",
      "3/3 [==============================] - 0s 888us/step - loss: 355034.8438\n",
      "5/5 [==============================] - 0s 798us/step - loss: 464819.9688\n",
      "3/3 [==============================] - 0s 764us/step - loss: 548912.1250\n",
      "5/5 [==============================] - 0s 682us/step - loss: 452637.8750\n",
      "3/3 [==============================] - 0s 714us/step - loss: 571902.6250\n",
      "5/5 [==============================] - 0s 752us/step - loss: 561709.9375\n",
      "3/3 [==============================] - 0s 772us/step - loss: 355419.4688\n",
      "5/5 [==============================] - 0s 724us/step - loss: 464805.7188\n",
      "3/3 [==============================] - 0s 745us/step - loss: 548953.5625\n",
      "5/5 [==============================] - 0s 674us/step - loss: 453308.3750\n",
      "3/3 [==============================] - 0s 756us/step - loss: 572363.3125\n",
      "5/5 [==============================] - 0s 705us/step - loss: 561202.3125\n",
      "3/3 [==============================] - 0s 734us/step - loss: 355128.8750\n",
      "5/5 [==============================] - 0s 705us/step - loss: 465064.9062\n",
      "3/3 [==============================] - 0s 764us/step - loss: 549050.5000\n",
      "5/5 [==============================] - 0s 678us/step - loss: 453113.5938\n",
      "3/3 [==============================] - 0s 721us/step - loss: 572278.0000\n",
      "5/5 [==============================] - 0s 717us/step - loss: 561141.0000\n",
      "3/3 [==============================] - 0s 730us/step - loss: 354826.7500\n",
      "5/5 [==============================] - 0s 725us/step - loss: 464678.7188\n",
      "3/3 [==============================] - 0s 751us/step - loss: 548763.5625\n",
      "5/5 [==============================] - 0s 684us/step - loss: 452874.2500\n",
      "3/3 [==============================] - 0s 681us/step - loss: 571929.0625\n",
      "5/5 [==============================] - 0s 710us/step - loss: 561011.5625\n",
      "3/3 [==============================] - 0s 750us/step - loss: 354995.5312\n",
      "5/5 [==============================] - 0s 694us/step - loss: 465119.4688\n",
      "3/3 [==============================] - 0s 697us/step - loss: 548937.1875\n",
      "5/5 [==============================] - 0s 690us/step - loss: 452956.2812\n",
      "3/3 [==============================] - 0s 778us/step - loss: 572059.9375\n",
      "5/5 [==============================] - 0s 700us/step - loss: 561105.6875\n",
      "3/3 [==============================] - 0s 718us/step - loss: 354859.4062\n",
      "5/5 [==============================] - 0s 737us/step - loss: 465373.8125\n",
      "3/3 [==============================] - 0s 829us/step - loss: 549149.0000\n",
      "5/5 [==============================] - 0s 727us/step - loss: 452978.3750\n",
      "3/3 [==============================] - 0s 829us/step - loss: 571566.0625\n",
      "5/5 [==============================] - 0s 795us/step - loss: 560779.0000\n",
      "3/3 [==============================] - 0s 795us/step - loss: 354463.2812\n",
      "5/5 [==============================] - 0s 735us/step - loss: 464746.4375\n",
      "3/3 [==============================] - 0s 769us/step - loss: 549173.4375\n",
      "5/5 [==============================] - 0s 702us/step - loss: 452681.5938\n",
      "3/3 [==============================] - 0s 734us/step - loss: 572263.0000\n",
      "5/5 [==============================] - 0s 743us/step - loss: 561460.1250\n",
      "3/3 [==============================] - 0s 737us/step - loss: 355498.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 649us/step - loss: 465082.5000\n",
      "3/3 [==============================] - 0s 706us/step - loss: 549578.2500\n",
      "5/5 [==============================] - 0s 701us/step - loss: 452860.2500\n",
      "3/3 [==============================] - 0s 727us/step - loss: 572495.6250\n",
      "5/5 [==============================] - 0s 641us/step - loss: 561467.3750\n",
      "3/3 [==============================] - 0s 786us/step - loss: 355673.7188\n",
      "5/5 [==============================] - 0s 748us/step - loss: 465242.9062\n",
      "3/3 [==============================] - 0s 690us/step - loss: 549670.7500\n",
      "5/5 [==============================] - 0s 726us/step - loss: 453091.5000\n",
      "3/3 [==============================] - 0s 697us/step - loss: 572715.0000\n",
      "5/5 [==============================] - 0s 687us/step - loss: 561044.2500\n",
      "3/3 [==============================] - 0s 721us/step - loss: 355213.6875\n",
      "5/5 [==============================] - 0s 695us/step - loss: 464669.1562\n",
      "3/3 [==============================] - 0s 652us/step - loss: 549082.3125\n",
      "5/5 [==============================] - 0s 743us/step - loss: 453181.4688\n",
      "3/3 [==============================] - 0s 814us/step - loss: 572855.5000\n",
      "5/5 [==============================] - 0s 697us/step - loss: 561970.8125\n",
      "3/3 [==============================] - 0s 775us/step - loss: 355981.0938\n",
      "5/5 [==============================] - 0s 675us/step - loss: 464781.0625\n",
      "3/3 [==============================] - 0s 739us/step - loss: 549077.8750\n",
      "5/5 [==============================] - 0s 756us/step - loss: 453114.5000\n",
      "3/3 [==============================] - 0s 775us/step - loss: 572645.0000\n",
      "5/5 [==============================] - 0s 750us/step - loss: 561308.3750\n",
      "3/3 [==============================] - 0s 826us/step - loss: 355375.4062\n",
      "5/5 [==============================] - 0s 794us/step - loss: 464700.8438\n",
      "3/3 [==============================] - 0s 780us/step - loss: 549158.5000\n",
      "5/5 [==============================] - 0s 683us/step - loss: 452996.3750\n",
      "3/3 [==============================] - 0s 745us/step - loss: 572569.0625\n",
      "5/5 [==============================] - 0s 713us/step - loss: 560732.6875\n",
      "3/3 [==============================] - 0s 817us/step - loss: 354910.6562\n",
      "5/5 [==============================] - 0s 696us/step - loss: 465335.0938\n",
      "3/3 [==============================] - 0s 881us/step - loss: 549787.0000\n",
      "5/5 [==============================] - 0s 759us/step - loss: 453321.2812\n",
      "3/3 [==============================] - 0s 771us/step - loss: 573028.8125\n",
      "5/5 [==============================] - 0s 693us/step - loss: 561006.2500\n",
      "3/3 [==============================] - 0s 727us/step - loss: 355174.3125\n",
      "5/5 [==============================] - 0s 822us/step - loss: 465173.0938\n",
      "3/3 [==============================] - 0s 754us/step - loss: 549621.2500\n",
      "5/5 [==============================] - 0s 768us/step - loss: 453092.6562\n",
      "3/3 [==============================] - 0s 826us/step - loss: 572648.1250\n",
      "5/5 [==============================] - 0s 708us/step - loss: 560343.1250\n",
      "3/3 [==============================] - 0s 861us/step - loss: 354833.3125\n",
      "5/5 [==============================] - 0s 734us/step - loss: 464820.6250\n",
      "3/3 [==============================] - 0s 799us/step - loss: 549289.3125\n",
      "5/5 [==============================] - 0s 764us/step - loss: 453443.3438\n",
      "3/3 [==============================] - 0s 777us/step - loss: 573070.8750\n",
      "5/5 [==============================] - 0s 707us/step - loss: 561458.4375\n",
      "3/3 [==============================] - 0s 783us/step - loss: 355558.3750\n",
      "7/7 [==============================] - 0s 667us/step - loss: 483067.0312\n",
      "En İyi Parametreler:  {'lr': 0.01, 'optimizer': 'adam', 'units1': 128, 'units2': 128}\n",
      "En İyi R2 Skoru:  -472546.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/batuhanbilgili/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "81 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "81 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/batuhanbilgili/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/batuhanbilgili/opt/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 164, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"/var/folders/t5/k116mkp91b14gpcf_ggn7cn80000gn/T/ipykernel_78609/2088236660.py\", line 11, in create_model\n",
      "    optimizer = SGD(lr=lr) # SGD optimizer ve learning rate'i ayarla\n",
      "NameError: name 'SGD' is not defined\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/batuhanbilgili/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [-488340.41666667 -487638.77083333 -484839.05208333 -486625.03125\n",
      " -484301.72916667 -478976.97916667 -484118.375      -479681.55208333\n",
      " -472546.25                    nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan -492542.19791667 -492483.0625\n",
      " -492084.96875    -492078.07291667 -492148.58333333 -492051.75\n",
      " -491896.05208333 -491952.17708333 -491726.11458333              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      " -492311.63541667 -492582.53125    -492533.14583333 -492639.63541667\n",
      " -492366.09375    -492212.73958333 -492663.375      -492367.5625\n",
      " -492639.52083333              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Yapay sinir ağı modelini tanımlayın\n",
    "def create_model(optimizer='adam', units1=64, units2=32, lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units1, activation='relu', input_dim=X_train.shape[1])) # Giriş katmanı\n",
    "    model.add(Dense(units=units2, activation='relu')) # Gizli katman\n",
    "    model.add(Dense(units=1)) # Çıkış katmanı\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(lr=lr) # Adam optimizer ve learning rate'i ayarla\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(lr=lr) # SGD optimizer ve learning rate'i ayarla\n",
    "        \n",
    "    model.compile(optimizer=optimizer, loss='mse') # Modeli derleme\n",
    "    return model\n",
    "\n",
    "# KerasRegressor wrapper kullanarak modeli oluşturun\n",
    "regressor = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "# Model tuning için parametre grid'i\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd'], # optimizer seçenekleri\n",
    "    'units1': [32, 64, 128], # birinci gizli katmandaki nöron sayısı seçenekleri\n",
    "    'units2': [32, 64, 128], # ikinci gizli katmandaki nöron sayısı seçenekleri\n",
    "    'lr': [0.01, 0.001, 0.0001] # learning rate seçenekleri\n",
    "}\n",
    "\n",
    "# GridSearchCV kullanarak model tuning'i gerçekleştirin\n",
    "grid = GridSearchCV(regressor, param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# En iyi parametreleri ve skorları yazdırın\n",
    "print(\"En İyi Parametreler: \", grid.best_params_)\n",
    "print(\"En İyi R2 Skoru: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e3c8db1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 616us/step - loss: 490515.9688\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 717us/step - loss: 472831.7500\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 706us/step - loss: 429514.5625\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 680us/step - loss: 342566.2812\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 670us/step - loss: 220665.4375\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 796us/step - loss: 155780.3438\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 780us/step - loss: 147925.3438\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 730us/step - loss: 139567.3125\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 620us/step - loss: 118520.0781\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 750us/step - loss: 112516.6562\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 728us/step - loss: 108368.9609\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 636us/step - loss: 104712.1328\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 617us/step - loss: 100191.9297\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 681us/step - loss: 98822.6797\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 648us/step - loss: 98512.8750\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 644us/step - loss: 97246.7031\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 688us/step - loss: 94096.9531\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 614us/step - loss: 91871.4453\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 642us/step - loss: 91168.0703\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 631us/step - loss: 90308.1719\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 653us/step - loss: 89478.4688\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 648us/step - loss: 89235.6562\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 668us/step - loss: 88922.4062\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 657us/step - loss: 89167.5469\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 666us/step - loss: 87705.1953\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 613us/step - loss: 89674.0391\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 599us/step - loss: 90240.2734\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 694us/step - loss: 84688.4141\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 589us/step - loss: 89559.5312\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 630us/step - loss: 84027.8516\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 695us/step - loss: 88291.7891\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 625us/step - loss: 84860.6875\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 639us/step - loss: 85210.8906\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 687us/step - loss: 89703.7031\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 577us/step - loss: 85585.8281\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 653us/step - loss: 83932.3672\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 617us/step - loss: 83077.7578\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 610us/step - loss: 83214.5625\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 677us/step - loss: 82371.5000\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 81814.8516\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 610us/step - loss: 81993.4141\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 710us/step - loss: 80768.2109\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 521us/step - loss: 81048.3750\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 648us/step - loss: 80956.9062\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 654us/step - loss: 80043.1953\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 612us/step - loss: 80831.8281\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 680us/step - loss: 79643.9219\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 655us/step - loss: 80202.6875\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 603us/step - loss: 79954.0469\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 650us/step - loss: 78813.1250\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 629us/step - loss: 78772.8516\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 642us/step - loss: 78982.8438\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 662us/step - loss: 78355.9531\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 680us/step - loss: 77046.1094\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 619us/step - loss: 77373.5938\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 654us/step - loss: 77520.5703\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 642us/step - loss: 77419.5547\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 666us/step - loss: 76492.1406\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 643us/step - loss: 77969.1953\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 588us/step - loss: 78630.4375\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 575us/step - loss: 77413.9375\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 695us/step - loss: 77246.4453\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 630us/step - loss: 75235.1719\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 678us/step - loss: 76120.6484\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 616us/step - loss: 76934.4219\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 581us/step - loss: 75700.2578\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 610us/step - loss: 74654.6719\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 643us/step - loss: 74757.2109\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 600us/step - loss: 74563.1094\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 655us/step - loss: 79340.0781\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 586us/step - loss: 78467.9922\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 595us/step - loss: 74315.4062\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 706us/step - loss: 75237.3828\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 614us/step - loss: 73789.4609\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 649us/step - loss: 75695.7031\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 651us/step - loss: 74519.0547\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 645us/step - loss: 76387.4844\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 610us/step - loss: 74493.7188\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 623us/step - loss: 74699.0234\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 597us/step - loss: 71476.5000\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 614us/step - loss: 75063.6094\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 582us/step - loss: 75801.7188\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 73368.2422\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 656us/step - loss: 71813.4297\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 643us/step - loss: 72041.2422\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 693us/step - loss: 69975.7344\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 629us/step - loss: 69835.8750\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 643us/step - loss: 69322.3125\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 700us/step - loss: 68081.8203\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 656us/step - loss: 68424.8203\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 709us/step - loss: 69936.9609\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 660us/step - loss: 68250.5547\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 632us/step - loss: 67481.4453\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 700us/step - loss: 68795.4531\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 692us/step - loss: 67206.6797\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 632us/step - loss: 66068.1641\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 597us/step - loss: 66671.9844\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 605us/step - loss: 65339.3750\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 576us/step - loss: 65812.2344\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 594us/step - loss: 65557.9062\n",
      "3/3 [==============================] - 0s 644us/step\n",
      "MSE:  355.3377564947648\n",
      "R2:  0.4167251251225196\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.01)\n",
    "ysa_model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "ysa_model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1)\n",
    "\n",
    "y_pred = ysa_model.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE: \", np.sqrt(mse))\n",
    "print(\"R2: \", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
